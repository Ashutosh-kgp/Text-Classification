{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np \n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "from nltk.stem.porter import *\n",
    "from sklearn.svm import SVC\n",
    "import pickle \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import preprocessing \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    " \n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pre_processing(text):\n",
    " \n",
    "    expr = re.compile('\\d{2}/\\d{2}/\\d{4}')\n",
    "    line = re.sub(expr,'',text )\n",
    "    expr = re.compile('\\d{2}:\\d{2}:\\d{2}')\n",
    "    text = re.sub(expr, '', line)\n",
    "    text = re.sub(\"\\d\", \"\", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pattern = re.compile('[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\.:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]')\n",
    "    tokens = [w for w in tokens if w not in stopword_list]\n",
    "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    " \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_convert(predictions):\n",
    "    \n",
    "    int_predict = []\n",
    "    \n",
    "    for i in range(0,len(predictions)):\n",
    "        \n",
    "        result = np.where(predictions[i] == np.amax(predictions[i]))\n",
    "\n",
    "        int_predict.append(result[0][0])\n",
    "        \n",
    "    return int_predict\n",
    "\n",
    "def inference(input_query):\n",
    "     #Load file weight\n",
    "     \n",
    "        \n",
    "    filename = 'weights/lbl_enc.sav'\n",
    "    lbl_enc= pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    filename = 'weights/tfv_weights.sav'\n",
    "    tfv = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    filename = 'weights/svd_weights.sav'\n",
    "    svd = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    filename = 'weights/scl_weights.sav'\n",
    "    scl = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    filename = 'weights/clf_weights.sav'\n",
    "    clf = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    input_query = tfv.transform(input_query)\n",
    "    input_query = svd.transform(input_query)\n",
    "    input_query = scl.transform(input_query)\n",
    "    \n",
    "   \n",
    "     \n",
    "    predictions = clf.predict_proba(input_query)\n",
    "     \n",
    "    \n",
    "    int_predict = integer_convert(predictions)\n",
    "     \n",
    "    labels =  lbl_enc.inverse_transform(int_predict)\n",
    "    \n",
    "    print('Label:{}'.format(labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:['EMSE SMARTS']\n"
     ]
    }
   ],
   "source": [
    "input_query = '''*** NOTES 22/01/2019 12:16:44 wsluser Action Type: PM Team\n",
    "*** HELPWWW        Web Access    wsluser\n",
    "Please configure ORKNEY_NHS_SIP  onto the DLSS\n",
    "This customer solution is expected to have 2 devices under management.\n",
    "The network will be connected to  \n",
    "      \n",
    "NetcoolRainbow                              \n",
    "\n",
    "\n",
    "This network uses VoIP \n",
    "(delete as appropriate)\n",
    "\n",
    "These devices and their notifications need to be visible in the following GSAM views, and buckets.\n",
    "GSAM XXX\n",
    "BUCKET YYY\n",
    "e.g. Thurso GSAM , off shore bucket\n",
    "Please include this statement in all MSFBT contracts.  Auto ticketing must be switched on for this Contract\n",
    "\n",
    "Thank You\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "*** RESEARCH LOG 28/01/2019 08:03:35 nxmcr08 Action Type: Action Taken\n",
    "*** UKEEMSESMARTS        Mohamed Riswan  +91 9524304152  nxmcr08\n",
    "Hi Team,\n",
    "\n",
    "Please add below network.\n",
    "\n",
    "ORKNEY_NHS_SIP\n",
    "\n",
    "in rdl07163app124 - APM15-S-NET-roc\n",
    "\n",
    "and cbl07163app132 - APM15-S-NET-car\n",
    "\n",
    "After adding the network, please dispatch the case back to us.\n",
    "\n",
    "Thanks and Regards,\n",
    "Mohamed Riswan | SMARTS ASG\n",
    "\n",
    " \n",
    "*** RESEARCH LOG 29/01/2019 08:48:07 nuvjk53 Action Type: Action Taken\n",
    "*** Master UKGSEMSEMSTR        Vishal Kumar  70440 860 65  nuvjk53\n",
    "HI team ,\n",
    "\n",
    "could you please let us know that this network will be managed by ?\n",
    "\n",
    "management ip or customer ip or both ?\n",
    "\n",
    " \n",
    "*** RESEARCH LOG 29/01/2019 08:56:52 nxmcr08 Action Type: Action Taken\n",
    "*** UKEEMSESMARTS        Mohamed Riswan  +91 952'''\n",
    "\n",
    "input_query = pre_processing(input_query)\n",
    "inference([input_query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
